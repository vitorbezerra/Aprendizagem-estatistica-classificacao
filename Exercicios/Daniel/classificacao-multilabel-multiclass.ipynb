{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Classificadores Lineares\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Classificadores KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Classificadores Naive Nayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Classificadores Arvores de Decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy.io import arff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com Multiplas Classes\n",
    "* A resposta (y) ́e umas das multiplas classes possıveis\n",
    "\n",
    "### Usando base Iris para teste\n",
    "#### Variáveis independentes:\n",
    "\n",
    "* Largura de pétala\n",
    "* altura de pétala\n",
    "* Largura de sépala\n",
    "* altura de sépala\n",
    "\n",
    "#### Variável a ser predita:\n",
    "* Predizer: species (Nesse dataset 3 possíveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para datasets com muitas variáveis independentes é possível eliminar apenas o label usando drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "X = df.drop(['species'], axis=1)\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print( df['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi_class{‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "\n",
    "* Se a opção escolhida for \"ovr\", um problema binário é montado para cada rótulo. \n",
    "* Para \"multinomial\", a perda minimizada é o ajuste de perda multinomial em toda a distribuição de probabilidade, mesmo se houber apenas duas classes\n",
    "* \"Multinomial\" fica indisponível quando solver = 'liblinear'. \n",
    "'Auto' seleciona 'ovr' se os dados são binários ou se solver = 'liblinear' caso contrário, seleciona 'multinomial'.\n",
    "\n",
    "ref: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "* Algoritmo a ser usado na otimização.\n",
    "\n",
    "* Para conjuntos de dados pequenos, 'liblinear' é uma boa opção, enquanto 'sag' e 'saga' são mais rápidos para conjuntos grandes de dados\n",
    "\n",
    "* Apenas 'newton-cg', 'sag', 'saga' e 'lbfgs' lidam com a perda multinomial; \n",
    "\n",
    "* \"Liblinear\" é limitado a esquemas de um contra o resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd_clf = SGDClassifier(random_state=42)\n",
    "#sgd_clf = LogisticRegression(multi_class='multinomial',solver='sag')\n",
    "# 'newton-cg', 'sag', 'saga' e 'lbfgs\n",
    "sgd_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A matriz de confusão gerada para datasets com variável alvo possuindo mais de uma classe, é quadrada sendo seu tamanho igual a quantidade de classes\n",
    "\n",
    "### Para esse caso três espécies, portanto matriz quadrada 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         6\n",
      "  versicolor       1.00      1.00      1.00         2\n",
      "   virginica       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretação\n",
    "* As classes setosa e versicolor não tiverem erros (precision 1)\n",
    "* A classe virginica houve 5 erros (precision 0.69)\n",
    "* versicolor possui recall 0.71 => TP / TP+FN (12 / 12 + 5) => 0.7\n",
    "* nesse caso, instancias da classe virginica todos foram confundidos com versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando múltiplas classes com KNN, Arvore e Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         6\n",
      "  versicolor       1.00      1.00      1.00         2\n",
      "   virginica       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvore de Decição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         6\n",
      "  versicolor       1.00      1.00      1.00         2\n",
      "   virginica       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         6\n",
      "  versicolor       1.00      1.00      1.00         2\n",
      "   virginica       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de classificador um contra todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         6\n",
      "  versicolor       1.00      1.00      1.00         2\n",
      "   virginica       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de classificador aos pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 2 0]\n",
      " [0 0 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         6\n",
      "  versicolor       1.00      1.00      1.00         2\n",
      "   virginica       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício Mnist\n",
    "* 786 colunas de características\n",
    "* coluna label identifica o número\n",
    "* crie um dataframe para representar a base mnist\n",
    "* crie um classificador de multiplas classes (usando a coluna label) como alvo\n",
    "* interprete o resultado\n",
    "* Qual valor (entre 0 a 9) o classificador teve mais sucesso em identificar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resolva o exercicio aqui...\n",
    "\n",
    "dfTrain = pd.read_csv(\"./mnist_train.csv\")\n",
    "dfTest = pd.read_csv(\"./mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dfTrain.drop(\"label\", axis = 1)\n",
    "X_test = dfTest.drop(\"label\", axis = 1)\n",
    "y_train = dfTrain[\"label\"]\n",
    "y_test = dfTest[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 974    1    1    0    0    1    2    1    0    0]\n",
      " [   0 1133    2    0    0    0    0    0    0    0]\n",
      " [  10    9  996    2    0    0    0   13    2    0]\n",
      " [   0    2    4  976    1   13    1    7    3    3]\n",
      " [   1    6    0    0  950    0    4    2    0   19]\n",
      " [   6    1    0   11    2  859    5    1    3    4]\n",
      " [   5    3    0    0    3    3  944    0    0    0]\n",
      " [   0   21    5    0    1    0    0  991    0   10]\n",
      " [   8    2    4   16    8   11    3    4  914    4]\n",
      " [   4    5    2    8    9    2    1    8    2  968]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.96      1.00      0.98      1135\n",
      "           2       0.98      0.97      0.97      1032\n",
      "           3       0.96      0.97      0.96      1010\n",
      "           4       0.98      0.97      0.97       982\n",
      "           5       0.97      0.96      0.96       892\n",
      "           6       0.98      0.99      0.98       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.99      0.94      0.96       974\n",
      "           9       0.96      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3, n_jobs=12)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOBAGEM DANIEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Total\"] = X_train.iloc[:,0:784].sum(axis = 1)\n",
    "X_test[\"Total\"] = X_test.iloc[:,0:784].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27525],\n",
       "       [31095],\n",
       "       [19443],\n",
       "       ...,\n",
       "       [22132],\n",
       "       [20428],\n",
       "       [20920]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train[\"Total\"]).reshape(60000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 980    0    0    0    0    0    0    0    0    0]\n",
      " [1135    0    0    0    0    0    0    0    0    0]\n",
      " [1032    0    0    0    0    0    0    0    0    0]\n",
      " [1010    0    0    0    0    0    0    0    0    0]\n",
      " [ 982    0    0    0    0    0    0    0    0    0]\n",
      " [ 892    0    0    0    0    0    0    0    0    0]\n",
      " [ 958    0    0    0    0    0    0    0    0    0]\n",
      " [1028    0    0    0    0    0    0    0    0    0]\n",
      " [ 974    0    0    0    0    0    0    0    0    0]\n",
      " [1009    0    0    0    0    0    0    0    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      1.00      0.18       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(np.array(X_train[\"Total\"]).reshape(len(X_train),-1), np.array(y_train))\n",
    "\n",
    "y_pred = model.predict(np.array(X_test[\"Total\"]).reshape(len(X_test),-1))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOBAGEM DANIEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.453933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200433</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.889270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.042472</td>\n",
       "      <td>3.956189</td>\n",
       "      <td>2.839845</td>\n",
       "      <td>1.686770</td>\n",
       "      <td>1.678283</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label      1x1      1x2      1x3      1x4      1x5      1x6  \\\n",
       "count  60000.000000  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0   \n",
       "mean       4.453933      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.889270      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           1x7      1x8      1x9  ...         28x19         28x20  \\\n",
       "count  60000.0  60000.0  60000.0  ...  60000.000000  60000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.200433      0.088867   \n",
       "std        0.0      0.0      0.0  ...      6.042472      3.956189   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "              28x21         28x22         28x23       28x24    28x25    28x26  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.0000  60000.0  60000.0   \n",
       "mean       0.045633      0.019283      0.015117      0.0020      0.0      0.0   \n",
       "std        2.839845      1.686770      1.678283      0.3466      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "max      253.000000    253.000000    254.000000     62.0000      0.0      0.0   \n",
       "\n",
       "         28x27    28x28  \n",
       "count  60000.0  60000.0  \n",
       "mean       0.0      0.0  \n",
       "std        0.0      0.0  \n",
       "min        0.0      0.0  \n",
       "25%        0.0      0.0  \n",
       "50%        0.0      0.0  \n",
       "75%        0.0      0.0  \n",
       "max        0.0      0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mnist_train.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação entre variável indepentes X e variáveis alvo Y \n",
    "* Mais de uma classe possível para cada instância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  método scipy.io.arff.loadarff \n",
    "* Método para leitura de arquivos no formato Attribute-Relation File Format (ARFF)\n",
    "* Fonte de bases de dados multilabel no formato arff : https://github.com/tsoumakas/mulan/tree/master/data/multi-label\n",
    "* (yeast): base de dados para estudos de proteínas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = scipy.io.arff.loadarff('yeast-train.arff.txt')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação de dados\n",
    "* Codificação de variáveis categóricas\n",
    "* Separação em Treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/donghi/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14'], axis=1)\n",
    "Y = df[['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y['class1'] = le.fit_transform(Y['Class1'])\n",
    "Y['class2'] = le.fit_transform(Y['Class2'])\n",
    "Y['class3'] = le.fit_transform(Y['Class3'])\n",
    "Y['class4'] = le.fit_transform(Y['Class4'])\n",
    "Y['class5'] = le.fit_transform(Y['Class5'])\n",
    "Y['class6'] = le.fit_transform(Y['Class6'])\n",
    "Y['class7'] = le.fit_transform(Y['Class7'])\n",
    "Y['class8'] = le.fit_transform(Y['Class8'])\n",
    "Y['class9'] = le.fit_transform(Y['Class9'])\n",
    "Y['class10'] = le.fit_transform(Y['Class10'])\n",
    "Y['class11'] = le.fit_transform(Y['Class11'])\n",
    "Y['class12'] = le.fit_transform(Y['Class12'])\n",
    "Y['class13'] = le.fit_transform(Y['Class13'])\n",
    "Y['class14'] = le.fit_transform(Y['Class14'])\n",
    "\n",
    "Y = Y.drop(['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando regressão logística a dados multi-classe\n",
    "* Método apresenta erro de mal-formato de Y, indicando que não aceita múltiplas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (1350, 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-63fd523e844a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msgd_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msgd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    758\u001b[0m                         dtype=None)\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ambDanielFiep/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (1350, 14)"
     ]
    }
   ],
   "source": [
    "sgd_clf = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "y_pred = sgd_clf.predict(X_train)\n",
    "print(classification_report(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerando apenas uma classe como variável a ser predita\n",
    "* Regressão Logística funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = Y[['class1']]\n",
    "\n",
    "sgd_clf = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "#sgd_clf = LogisticRegression()\n",
    "sgd_clf.fit(X, YY)\n",
    "y_pred = sgd_clf.predict(X)\n",
    "print(classification_report(YY, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No scikit-learn alguns métodos aceitam dataset multiclasse: como o DecisionTreeClassifier por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = DecisionTreeClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outro exemplo de método que aceita múltiplas classes por instância:\n",
    "* import sklearn.ensemble.ExtraTreesClassifier\n",
    "* import sklearn.neighbors.KNeighborsClassifier\n",
    "* import sklearn.neighbors.RadiusNeighborsClassifier\n",
    "* import sklearn.ensemble.RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = KNeighborsClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando modelos:\n",
    "\n",
    "* Micro average (média do total de verdadeiros positivos, falsos negativos e falsos positivos) para múltiplas classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício\n",
    "### Dataset de Paisagens: \n",
    "\n",
    "* 294 atributos para descrever a imagem \n",
    "* 6 colunas para predição: Beach Sunset FallFoliage Field Mountain Urban\n",
    "\n",
    "Arquivo: scene.arff\n",
    "Fonte: https://datahub.io/machine-learning/scene\n",
    "\n",
    "Faça um classificador multiclassse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = scipy.io.arff.loadarff(\"./scene.arff\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"Beach\", \"Sunset\", \"FallFoliage\", \"Field\", \"Mountain\", \"Urban\"], axis=1)\n",
    "y = df[[\"Beach\", \"Sunset\", \"FallFoliage\", \"Field\", \"Mountain\", \"Urban\"]]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y['beach'] = le.fit_transform(y['Beach'])\n",
    "y['sunset'] = le.fit_transform(y['Sunset'])\n",
    "y['fallFoliage'] = le.fit_transform(y['FallFoliage'])\n",
    "y['field'] = le.fit_transform(y['Field'])\n",
    "y['mountain'] = le.fit_transform(y['Mountain'])\n",
    "y['urban'] = le.fit_transform(y['Urban'])\n",
    "\n",
    "\n",
    "y = y.drop([\"Beach\", \"Sunset\", \"FallFoliage\", \"Field\", \"Mountain\", \"Urban\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3, n_jobs=12)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ambDanielFiep] *",
   "language": "python",
   "name": "conda-env-ambDanielFiep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
